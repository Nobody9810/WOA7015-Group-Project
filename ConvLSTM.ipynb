{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnpPjKVD68eH"
   },
   "source": [
    "## Setup\n",
    "Begin by installing and importing some necessary libraries\n",
    "\n",
    "#### The way this tutorial uses the `TimeDistributed` layer requires TF>=2.10\n",
    "pip install -U \"tensorflow>=2.10.0\"\n",
    "\n",
    "pip install remotezip tqdm opencv-python\n",
    "pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "pip install imageio\n",
    "\n",
    "import imageio\n",
    "\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RYQIJ9C6BVH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import cv2 # process video files\n",
    "\n",
    "import imageio\n",
    "from tensorflow_docs.vis import embed #for embedding data in a Jupyter notebook\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbhwWLLM7FXo"
   },
   "source": [
    "## Download dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVIgj-jIA8U8",
    "outputId": "79d45470-27d8-4351-c605-0c6802d140c8"
   },
   "outputs": [],
   "source": [
    "# folder path that you store the video file and csv file\n",
    "dataset_file_path = \"C:/Users/kwjia/Downloads/\"\n",
    "\n",
    "dataset_filepath = dataset_file_path+\"final_exam/input_data_new.csv\"\n",
    "df = pd.read_csv(dataset_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5gs6j982P3e"
   },
   "source": [
    "## Create frames from each video file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_EpG1896nJy"
   },
   "source": [
    "Using pandas library to process dataframe and return to the seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-sNCzKj2P3f"
   },
   "outputs": [],
   "source": [
    "def convert_time_to_seconds(time_str):\n",
    "    h, m, s = map(int, time_str.split(':'))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "df[\"start_time_seconds\"]=df[\"Start_Time\"].apply(convert_time_to_seconds)\n",
    "df[\"end_time_seconds\"]=df[\"End_Time\"].apply(convert_time_to_seconds)\n",
    "class_list = df.Movement_Name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract frame and video preprocessing process (frame skipping, frame resize, frame color code conversion, color code normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ucICTIp2uqH"
   },
   "outputs": [],
   "source": [
    "#Extract frame from video\n",
    "def extract_frame(path,start_time,end_time):\n",
    "  frame_list = []\n",
    "  SEQUENCE_LENGTH = 24\n",
    "\n",
    "  # Open the video file for reading\n",
    "  video_reader = cv2.VideoCapture(path)\n",
    "\n",
    "  # Get the frames per second (fps), start_frame, and end_frame for the specified video duration\n",
    "  fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "  frame_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  start_frame = int(start_time*fps)\n",
    "  end_frame = int(end_time*fps)\n",
    "  interval_frame = end_frame - start_frame\n",
    "\n",
    "  #calculate the skip frame number formula total duration of interval frame / sequence length\n",
    "  skip_frame_window = max(interval_frame/SEQUENCE_LENGTH,1)\n",
    "\n",
    "  # Get the height and width of the video frames\n",
    "  height = video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "  width = video_reader.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "  print(f'fps:{fps}, frame_cnt:{frame_count} interval_frame:{interval_frame}, height:{height}, width:{width}, start_frame:{start_frame},end_frame:{end_frame},skip:{skip_frame_window}')\n",
    "\n",
    "\n",
    "  # Set the video reader to the start frame\n",
    "  video_reader.set(cv2.CAP_PROP_POS_FRAMES,start_frame)\n",
    "  current_frame = start_frame\n",
    "\n",
    "  # Iterate through frames in the specified interval\n",
    "  while video_reader.isOpened() and math.ceil(current_frame) < end_frame:\n",
    "    ret, frame = video_reader.read()\n",
    "    if not ret:\n",
    "      break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    frame_rgb_opencv = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize the frame to a specific size (720x1280)\n",
    "    resized_frame = cv2.resize(frame_rgb_opencv,(128,128))\n",
    "\n",
    "    #normalize data to [0,1]\n",
    "    frame = tf.image.convert_image_dtype(resized_frame, tf.float32)\n",
    "      \n",
    "    # Append the resized frame to the frame_list\n",
    "    frame_list.append(frame)\n",
    "\n",
    "    # Set the video reader to the next frame position\n",
    "    video_reader.set(cv2.CAP_PROP_POS_FRAMES, int(current_frame + skip_frame_window) )\n",
    "\n",
    "    # Increment the current_frame by skip_frame_window\n",
    "    current_frame += skip_frame_window\n",
    "\n",
    "\n",
    "  # Release the video reader and close any remaining OpenCV windows\n",
    "  video_reader.release()\n",
    "  cv2.destroyAllWindows()\n",
    "    \n",
    "  # Return the list of extracted frames\n",
    "  return frame_list;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate input data as X and label as Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I69o_DLD2xRH",
    "outputId": "53ceaa35-6fe7-4751-8ead-f0aef7304f5c"
   },
   "outputs": [],
   "source": [
    "X = [] #Save the frame\n",
    "Y = [] #Save the lable\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "  start_time = row[\"start_time_seconds\"]\n",
    "  end_time = row[\"end_time_seconds\"]\n",
    "  path = dataset_file_path + row[\"GD_Path\"] # Get the vidoe file path\n",
    "  label = row[\"Movement_Name\"] # Get the Movement lable\n",
    "\n",
    "  Y.append(np.where(class_list == label)[0][0])\n",
    "  X.append(np.asarray(extract_frame(path,start_time,end_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the frames for the specific video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXwPGH4b20Sb"
   },
   "outputs": [],
   "source": [
    "def to_gif(images):\n",
    "  converted_images = np.clip(images*255, 0, 255).astype(np.uint8)\n",
    "  imageio.mimsave('./animation.gif', converted_images, fps=10)\n",
    "  return embed.embed_file('./animation.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_gif(X[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary encoding the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xt07vvMqKV6g"
   },
   "outputs": [],
   "source": [
    "#encode the label by using one-hot encoded\n",
    "one_hot_encoded_labels = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd4DR2aHmT8o"
   },
   "source": [
    "# Split dataset into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaT2p33nmaKH"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,one_hot_encoded_labels,test_size=0.2,\n",
    "                                                 shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfbida9-oH8_"
   },
   "source": [
    "# Construct Model - Using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoknMxbeoLF1"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import keras.models as kmodels\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def create_convlstm_model():\n",
    "  model = Sequential()\n",
    "  model.add(ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh',\n",
    "                       recurrent_dropout=0.2, data_format = \"channels_last\", return_sequences=True, input_shape=(24,128,128,3)))\n",
    "  model.add(MaxPooling3D(pool_size=(1,2,2),padding='same', data_format = \"channels_last\"))\n",
    "  model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "  model.add(ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh',\n",
    "                       recurrent_dropout=0.2, data_format = \"channels_last\", return_sequences=True))\n",
    "  model.add(MaxPooling3D(pool_size=(1,2,2),padding='same', data_format = \"channels_last\"))\n",
    "  model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "  model.add(ConvLSTM2D(filters=14, kernel_size=(3, 3), activation='tanh',\n",
    "                       recurrent_dropout=0.2, data_format = \"channels_last\", return_sequences=True))\n",
    "  model.add(MaxPooling3D(pool_size=(1,2,2),padding='same', data_format = \"channels_last\"))\n",
    "  model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "  model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), activation='tanh',\n",
    "                       recurrent_dropout=0.2, data_format = \"channels_last\", return_sequences=True))\n",
    "  model.add(MaxPooling3D(pool_size=(1,2,2),padding='same', data_format = \"channels_last\"))\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=class_list.size, activation='softmax'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwBNYVlzwOIq",
    "outputId": "aaf5cfe7-1311-4e91-a5a7-d0bc28989398"
   },
   "outputs": [],
   "source": [
    "convlstm_model = create_convlstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ghqawSX1Di8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras as keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVyAasNhz3TU"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=10,mode='min',restore_best_weights=True)\n",
    "\n",
    "convlstm_model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(X_train)\n",
    "\n",
    "convlstm_model_training_history = convlstm_model.fit(x=X_train_tensor,y = Y_train,epochs = 50, batch_size=4,shuffle=True,\n",
    "                                                     validation_split = 0.2, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = tf.convert_to_tensor(X_test)\n",
    "model_evaluation_history = convlstm_model.evaluate(X_test_tensor,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(convlstm_model_training_history.history['accuracy'])\n",
    "plt.plot(convlstm_model_training_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(convlstm_model_training_history.history['loss'])\n",
    "plt.plot(convlstm_model_training_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
